{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c10cf4",
   "metadata": {},
   "source": [
    "Grupo\n",
    "- Beatriz (2023007113)\n",
    "- Laviny (2023012893)\n",
    "- Caio (2022012333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a04930",
   "metadata": {},
   "source": [
    "#### Etapa 1\n",
    "- Nosso conjunto de dados é o Seeds\n",
    "- Foi sugerido retirar 1 ou 2 atributos para o trabalho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1caa7a",
   "metadata": {},
   "source": [
    "Realizar a importação dos dados a partir do CSV e definir os nomes das colunas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Nomes das colunas\n",
    "column_names = [\n",
    "    \"Área\",\n",
    "    \"Perímetro\",\n",
    "    \"Compacidade\",\n",
    "    \"Comprimento_grão\",\n",
    "    \"Largura_grão\",\n",
    "    \"Coeficiente_assimetria\",\n",
    "    \"Comprimento_sulco\",\n",
    "    \"Classe\"\n",
    "]\n",
    "\n",
    "# Leitura do CSV original\n",
    "csv_file = 'seeds_dataset.csv'\n",
    "df_original = pd.read_csv(csv_file, header=None, delim_whitespace=True, names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b38435",
   "metadata": {},
   "source": [
    "Imprimir informações básicas sobre o dataset. Essa etapa é importante para compreender a estrutura dos dados antes de iniciar as modificações e análises posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c85690",
   "metadata": {},
   "source": [
    "Uma verificação importante a ser feita é ver como está a distribuição das classes do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed27d7",
   "metadata": {},
   "source": [
    "A coluna \"Classe\" representa os rótulos do conjunto de dados. Como queremos descobrir padrões e estruturas sem usar a informação de rótulo, ou seja, a abordagem é não supervisionada. Removendo a coluna \"Classe\", garantimos que o algoritmo não seja influenciado por essa informação e possa identificar os grupos baseados somente nas características dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b62e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['Classe'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e46fc9",
   "metadata": {},
   "source": [
    "Nesta etapa, removemos a coluna \"Perímetro\" (além de \"Classe\") para criar um conjunto modificado dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X = df_original.drop(columns=[\"Perímetro\", \"Classe\"])\n",
    "y = df_original[\"Classe\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb21379",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28352ab7",
   "metadata": {},
   "source": [
    "#### Etapa 2\n",
    "- Aplicar uma técnica de classificação: KNN\n",
    "- Aplicar uma técnica de agrupamento: K-médias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f568f2b",
   "metadata": {},
   "source": [
    "Em seguida, separamos as features (X) dos rótulos (y) e dividimos os dados em conjuntos de treinamento e teste. O StandardScaler é utilizado para normalizar os dados, etapa essencial para o funcionamento adequado do algoritmo KNN que será aplicado para a tarefa de classificação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3527180",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Classificação com KNN (K-Nearest Neighbors)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)       \n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do KNN: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852e20e",
   "metadata": {},
   "source": [
    "Aqui, aplicamos o modelo KNN utilizando os dados originais. O modelo é treinado com os dados de treinamento e avaliado em termos de acurácia a partir do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_original.drop(columns=[\"Classe\"])\n",
    "y_full = df_original[\"Classe\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do KNN: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe7a26",
   "metadata": {},
   "source": [
    "Como obtemos a mesma acurácia para ambos, isso pode significar que o atributo que escolhemos para remover (Perímetro) é irrelevante, já que o desempenho se mostrou o mesmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae0778",
   "metadata": {},
   "source": [
    "Se realizarmos o teste retirando outro atributo, a acurácia muda. Por exemplo, se retirarmos a Compacidade ao invés do Perímetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09beee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = df_original.drop(columns=[\"Compacidade\", \"Classe\"])\n",
    "y_teste = df_original[\"Classe\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_teste, y_teste, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do KNN: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd69af",
   "metadata": {},
   "source": [
    "Quando o conjunto modificado apresenta acurácia melhor do que o conjunto original, isso pode indicar que o atributo removido estava introduzindo ruído ou informações redundantes. Ao eliminar essas variáveis que não contribuem com a capacidade do modelo de aprender padrões relevantes, o modelo consegue focar melhor na informação útil, resultando em um melhor desempenho na classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6e5b0",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea94871",
   "metadata": {},
   "source": [
    "#### Técnica de agrupamento: K-médias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0954d6",
   "metadata": {},
   "source": [
    "\n",
    "Para avaliar o desempenho do modelo de agrupamento KMeans utilizamos o 'silhouette_score'. Onde os valores variam entre -1 e 1. \n",
    "- próximo de 1: pontos bem agrupados\n",
    "- igual a 0: os pontos estão na borda entre os dois clusters\n",
    "- próximo de -1: pontos mal agrupados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ca1d3",
   "metadata": {},
   "source": [
    "Nesta parte, removemos as colunas \"Perímetro\" e \"Classe\" para evitar a interferência dos rótulos (que não devem ser usados em técnicas não supervisionadas). Em seguida, os dados são normalizados e o algoritmo K‑Médias é aplicado para formar dois clusters (o número de clusters pode ser ajustado conforme necessário). O Silhouette Score é calculado para avaliar a qualidade dos agrupamentos e, através de PCA, os clusters são visualizados em um gráfico de dispersão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans                       \n",
    "from sklearn.preprocessing import StandardScaler        \n",
    "from sklearn.decomposition import PCA                   \n",
    "from sklearn.metrics import silhouette_score             \n",
    "import matplotlib.pyplot as plt                          \n",
    "\n",
    "X = df_original.drop(columns=[\"Perímetro\", \"Classe\"])\n",
    "\n",
    "# Escalonamento dos dados, dados com média 0 e desvio padrão 1\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Definindo o número de clusters (aqui usamos 2 como exemplo)\n",
    "n_clusters = 2\n",
    "\n",
    "# Aplicando KMeans\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Avaliação do agrupamento usando o Silhouette Score\n",
    "sil = silhouette_score(X_scaled, labels)\n",
    "print(f\"Silhouette Score: {sil:.4f}\")\n",
    "\n",
    "# Visualização dos clusters usando PCA para redução de dimensionalidade\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"viridis\", alpha=0.7)\n",
    "plt.title(\"K‑médias no dataset modificado\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2467e83",
   "metadata": {},
   "source": [
    "Neste último trecho, mantemos todas as colunas dos dados (exceto \"Classe\", que é removida para evitar vazamento de informação) e aplicamos o mesmo procedimento de escalonamento, clusterização e avaliação dos grupos formados. Essa etapa possibilita a comparação entre o agrupamento obtido a partir do conjunto original e o conjunto modificado, permitindo uma análise comparativa dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81420a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_full = df_original.drop(columns=[\"Classe\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled_full = scaler.fit_transform(X_full)\n",
    "\n",
    "n_clusters = 2\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled_full)\n",
    "\n",
    "sil = silhouette_score(X_scaled_full, labels)\n",
    "print(f\"Silhouette Score: {sil:.4f}\")\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled_full)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"viridis\", alpha=0.7)\n",
    "plt.title(\"K‑médias no dataset original\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edaf48",
   "metadata": {},
   "source": [
    "Quando o Silhouette Score do conjunto original é maior do que o do conjunto modificado, isso sugere que os clusters formados com as features originais estão mais  separados. Os atributos removidos podem ter contribuído para uma melhor definição dos grupos, e sua retirada gerou em uma estrutura de agrupamento menos distinta "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8da44a",
   "metadata": {},
   "source": [
    "Se refizermos o teste mas agora retirando a Compacidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da68c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_original.drop(columns=[\"Compacidade\", \"Classe\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_clusters = 2\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "\n",
    "sil = silhouette_score(X_scaled, labels)\n",
    "print(f\"Silhouette Score: {sil:.4f}\")\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"viridis\", alpha=0.7)\n",
    "plt.title(\"K‑médias no dataset modificado\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d426f",
   "metadata": {},
   "source": [
    "Aconteceu da mesma forma que na classificação, o Silhouette Score ficou melhor nesse conjunto modificado, indicando que a remoção de Compacidade melhorou a estrutura dos grupos, deixando melhor separados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873633c",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz o Jupyter exibir tudo sem cortar\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056ced5",
   "metadata": {},
   "source": [
    "### Etapa 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a2db5",
   "metadata": {},
   "source": [
    "Classificação usando KNN\n",
    "\n",
    "Explicação do Relatório de Classificação:\n",
    "\n",
    "- precision: O quanto você pode confiar nas previsões do modelo. \"Se o modelo disse que é, qual a chance de realmente ser?\"\n",
    "\n",
    "- recall: Se o modelo consegue encontrar todos os casos positivos. \"De todos os que realmente são, quantos o modelo achou?\"\n",
    "\n",
    "- f1-score: Média entre precision e recall\n",
    "\n",
    "- support: Número de amostras reais de cada classe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1faaae",
   "metadata": {},
   "source": [
    "Parâmetros usados na classificação com KNN: \n",
    "\n",
    "- 'n_neighbors=5': o número de vizinhos usados para classificar cada ponto. Quanto menor o valor, mais sensível o modelo fica ao ruído.\n",
    "- 'weights': peso dos vizinhos, podem ser 'uniform' ou 'distance'.\n",
    "- 'metric': métrica da distância."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609469b4",
   "metadata": {},
   "source": [
    "Teste sem Perímetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X_teste = df_original.drop(columns=[\"Perímetro\", \"Classe\"])\n",
    "y_teste = df_original[\"Classe\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_teste, y_teste, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Loop por todas as combinações de hiperparâmetros\n",
    "for n in [3, 5, 7]:\n",
    "    for w in ['uniform', 'distance']:\n",
    "        for m in ['euclidean', 'manhattan']:\n",
    "            print(f\"\\nTestando com n_neighbors={n}, weights='{w}', metric='{m}'\")\n",
    "\n",
    "            # Instancia e treina o modelo\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=w, metric=m)\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Acurácia: {acc:.4f}\")\n",
    "            print(\"Relatório de Classificação:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(\"Matriz de Confusão:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0719f3c",
   "metadata": {},
   "source": [
    "Com n_neighbors = 7 a acurácia cai em dois exemplos de testes diferentes, enquanto que os outros teste a acurácia se mantém = 90."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c2742",
   "metadata": {},
   "source": [
    "#### Dataset sem a Compacidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_original.drop(columns=[\"Compacidade\", \"Classe\"])\n",
    "y = df_original[\"Classe\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Loop por todas as combinações de hiperparâmetros\n",
    "for n in [3, 5, 7]:\n",
    "    for w in ['uniform', 'distance']:\n",
    "        for m in ['euclidean', 'manhattan']:\n",
    "            print(f\"\\nTestando com n_neighbors={n}, weights='{w}', metric='{m}'\")\n",
    "\n",
    "            # Instancia e treina o modelo\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=w, metric=m)\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Acurácia: {acc:.4f}\")\n",
    "            print(\"Relatório de Classificação:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(\"Matriz de Confusão:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c31cb1",
   "metadata": {},
   "source": [
    "Em geral os testes resultaram acurácias altas. A mais baixa com a combinação de n_neighbors=7, weights='uniform', metric='euclidean'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb116a97",
   "metadata": {},
   "source": [
    "Dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_original.drop(columns=[\"Classe\"])\n",
    "y = df_original[\"Classe\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Loop por todas as combinações de hiperparâmetros\n",
    "for n in [3, 5, 7]:\n",
    "    for w in ['uniform', 'distance']:\n",
    "        for m in ['euclidean', 'manhattan']:\n",
    "            print(f\"\\nTestando com n_neighbors={n}, weights='{w}', metric='{m}'\")\n",
    "\n",
    "            # Instancia e treina o modelo\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=w, metric=m)\n",
    "            knn.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Acurácia: {acc:.4f}\")\n",
    "            print(\"Relatório de Classificação:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(\"Matriz de Confusão:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91744b",
   "metadata": {},
   "source": [
    "Houve 4 testes com acurácia = 0.89\n",
    "\n",
    "Apenas 2 testes com acurácia > 0.90\n",
    "\n",
    "Houve 6 testes com acurácia = 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba2aef",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef61d8",
   "metadata": {},
   "source": [
    "#### Teste com K-Means\n",
    "\n",
    "Parâmetros da técnica K-Means:\n",
    "- n_clusters: Quantidade de clusters.\n",
    "- init: Método de inicialização dos centróides.\n",
    "- n_init: Número de vezes que será executado com diferentes inicializações.\n",
    "- max_iter: Número de iterações por execução.\n",
    "- random_state: Semente para reprodutibilidade.\n",
    "- algorithm: Algoritmo que será usado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1497725",
   "metadata": {},
   "source": [
    "Teste sem Perímetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df_original.drop(columns=[\"Perímetro\", \"Classe\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Lista com configurações variadas de parâmetros\n",
    "parametros_kmeans = [\n",
    "    {\"n_clusters\": 3, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 300, \"algorithm\": \"lloyd\"},\n",
    "    {\"n_clusters\": 4, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 5, \"init\": \"k-means++\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 6, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 7, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 100, \"algorithm\": \"lloyd\"},\n",
    "    {\"n_clusters\": 8, \"init\": \"random\", \"n_init\": 15, \"max_iter\": 200, \"algorithm\": \"elkan\"},\n",
    "]\n",
    "\n",
    "# Redução de dimensionalidade para visualização\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Gráficos\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, params in enumerate(parametros_kmeans, 1):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        init=params[\"init\"],\n",
    "        n_init=params[\"n_init\"],\n",
    "        max_iter=params[\"max_iter\"],\n",
    "        algorithm=params[\"algorithm\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "\n",
    "    plt.subplot(3, 2, i)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"tab10\", alpha=0.7)\n",
    "    plt.title(f\"Clusters: {params['n_clusters']}, Init: {params['init']}\\n\"\n",
    "              f\"Iter: {params['max_iter']}, Algo: {params['algorithm']}\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "\n",
    "    # Mostrar Silhouette Score\n",
    "    plt.text(0.05, 0.95, f\"Silhouette: {sil:.4f}\", transform=plt.gca().transAxes,\n",
    "             fontsize=10, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95232a",
   "metadata": {},
   "source": [
    "Teste em dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc24bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_original.drop(columns=[\"Classe\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled_full = scaler.fit_transform(X_full)\n",
    "\n",
    "# Lista com configurações variadas de parâmetros\n",
    "parametros_kmeans = [\n",
    "    {\"n_clusters\": 2, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 300, \"algorithm\": \"lloyd\"},\n",
    "    {\"n_clusters\": 3, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 4, \"init\": \"k-means++\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 5, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 6, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 100, \"algorithm\": \"lloyd\"},\n",
    "    {\"n_clusters\": 7, \"init\": \"random\", \"n_init\": 15, \"max_iter\": 200, \"algorithm\": \"elkan\"},\n",
    "]\n",
    "\n",
    "# Redução de dimensionalidade para visualização\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Gráficos\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, params in enumerate(parametros_kmeans, 1):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        init=params[\"init\"],\n",
    "        n_init=params[\"n_init\"],\n",
    "        max_iter=params[\"max_iter\"],\n",
    "        algorithm=params[\"algorithm\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "\n",
    "    plt.subplot(3, 2, i)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"tab10\", alpha=0.7)\n",
    "    plt.title(f\"Clusters: {params['n_clusters']}, Init: {params['init']}\\n\"\n",
    "              f\"Iter: {params['max_iter']}, Algo: {params['algorithm']}\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "\n",
    "    # Mostrar Silhouette Score\n",
    "    plt.text(0.05, 0.95, f\"Silhouette: {sil:.4f}\", transform=plt.gca().transAxes,\n",
    "             fontsize=10, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd62c83",
   "metadata": {},
   "source": [
    "Teste sem Compacidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(columns=[\"Compacidade\", \"Classe\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Lista com configurações variadas de parâmetros\n",
    "parametros_kmeans = [\n",
    "    {\"n_clusters\": 3, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 300, \"algorithm\": \"lloyd\"},\n",
    "    {\"n_clusters\": 4, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 5, \"init\": \"k-means++\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 6, \"init\": \"random\", \"n_init\": 20, \"max_iter\": 500, \"algorithm\": \"elkan\"},\n",
    "    {\"n_clusters\": 7, \"init\": \"k-means++\", \"n_init\": 10, \"max_iter\": 100, \"algorithm\": \"lloyd\"},\n",
    "    {\"n_clusters\": 8, \"init\": \"random\", \"n_init\": 15, \"max_iter\": 200, \"algorithm\": \"elkan\"},\n",
    "]\n",
    "\n",
    "# Redução de dimensionalidade para visualização\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Gráficos\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, params in enumerate(parametros_kmeans, 1):\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=params[\"n_clusters\"],\n",
    "        init=params[\"init\"],\n",
    "        n_init=params[\"n_init\"],\n",
    "        max_iter=params[\"max_iter\"],\n",
    "        algorithm=params[\"algorithm\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "\n",
    "    plt.subplot(3, 2, i)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap=\"tab10\", alpha=0.7)\n",
    "    plt.title(f\"Clusters: {params['n_clusters']}, Init: {params['init']}\\n\"\n",
    "              f\"Iter: {params['max_iter']}, Algo: {params['algorithm']}\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "\n",
    "    # Mostrar Silhouette Score\n",
    "    plt.text(0.05, 0.95, f\"Silhouette: {sil:.4f}\", transform=plt.gca().transAxes,\n",
    "             fontsize=10, verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d67cc0",
   "metadata": {},
   "source": [
    "Dentre os três exemplos o melhor modo de fazer a análise foi sem a Compacidade, pois os pontos foram melhor agrupados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
